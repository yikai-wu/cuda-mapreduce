{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda, jit, float32\n",
    "import time\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_multiply_cpu(A, B):\n",
    "    cpu_start=time.time()\n",
    "   \n",
    "    C=np.dot(A, B)\n",
    "    cpu_time=time.time()-cpu_start\n",
    "    return C, cpu_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Define the CUDA kernel\n",
    "@cuda.jit\n",
    "def matrix_mult_kernel(A, B, C):\n",
    "    i, j, k = cuda.grid(3)\n",
    "    if i < A.shape[0] and j < B.shape[1] and k < A.shape[1]:\n",
    "        product = A[i, k] * B[k, j]\n",
    "        cuda.atomic.add(C, (i, j), product)\n",
    "\n",
    "def matrix_mult_gpu(A, B):\n",
    "    assert A.shape[1] == B.shape[0]\n",
    "\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    A_global_mem = cuda.to_device(A)\n",
    "    B_global_mem = cuda.to_device(B)\n",
    "    C_global_mem = cuda.device_array((A.shape[0], B.shape[1]), dtype=np.float32)\n",
    "\n",
    "    threads_per_block = (8, 8, 8)\n",
    "    blocks_per_grid_x = (A.shape[0] + threads_per_block[0] - 1) // threads_per_block[0]\n",
    "    blocks_per_grid_y = (B.shape[1] + threads_per_block[1] - 1) // threads_per_block[1]\n",
    "    blocks_per_grid_z = (A.shape[1] + threads_per_block[2] - 1) // threads_per_block[2]\n",
    "    blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y, blocks_per_grid_z)\n",
    "\n",
    "    cuda.synchronize()\n",
    "    kernel_start_time = time.time()\n",
    "    matrix_mult_kernel[blocks_per_grid, threads_per_block](A_global_mem, B_global_mem, C_global_mem)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    kernel_time = time.time() - kernel_start_time\n",
    "    \n",
    "    total_time = time.time() - total_start_time\n",
    "\n",
    "    C = C_global_mem.copy_to_host()\n",
    "\n",
    "    return C, kernel_time, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    TPB = 16\n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "    x, y = cuda.grid(2)\n",
    "\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    if x >= C.shape[0] and y >= C.shape[1]:\n",
    "        # Quit if (x, y) is outside of valid C boundary\n",
    "        return\n",
    "\n",
    "    # Each thread computes one element in the result matrix.\n",
    "    # The dot product is chunked into dot products of TPB-long vectors.\n",
    "    tmp = 0.\n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = A[x, ty + i * TPB]\n",
    "        sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "        # Wait until all threads finish preloading\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    C[x, y] = tmp\n",
    "\n",
    "def matrix_multiply_gpu(A, B):\n",
    "    TPB = 16\n",
    "    n, k = A.shape\n",
    "    k, m = B.shape\n",
    "    start = time.time()\n",
    "    A_device = cuda.to_device(A)\n",
    "    B_device = cuda.to_device(B)\n",
    "    C_device = cuda.device_array((n, m), dtype=np.float32)\n",
    "\n",
    "    threads_per_block = (TPB, TPB)\n",
    "    blocks_per_grid_x = math.ceil(m / TPB)\n",
    "    blocks_per_grid_y = math.ceil(n / TPB)\n",
    "\n",
    "    cuda.synchronize()\n",
    "    kernel_start_time = time.time()\n",
    "    fast_matmul[(blocks_per_grid_y, blocks_per_grid_x), threads_per_block](A_device, B_device, C_device)\n",
    "    cuda.synchronize()  # Wait for all GPU activity to finish\n",
    "    kernel_time = time.time()-kernel_start_time\n",
    "\n",
    "    C = C_device.copy_to_host()\n",
    "    gpu_time = time.time() - start\n",
    "    return C, kernel_time, gpu_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_matrix(n):\n",
    "    A = np.random.default_rng().standard_normal(size=(n,n), dtype='float32')\n",
    "    B = np.random.default_rng().standard_normal(size=(n,n), dtype='float32')\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_multiply_torch(A, B):\n",
    "    start_time = time.time()\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    A_device = torch.from_numpy(A).to(device)\n",
    "    B_device = torch.from_numpy(B).to(device)\n",
    "    kernel_start_time = time.time()\n",
    "    C_device = torch.matmul(A_device, B_device)\n",
    "    kernel_time = time.time()-kernel_start_time\n",
    "    C = C_device.cpu().numpy()\n",
    "    torch_time = time.time()-start_time\n",
    "    return C, torch_time, kernel_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n",
      "(10000, 10000)\n",
      "[[ -10.513769   -2.85761    35.93156  ...   86.984406  -62.66192\n",
      "    30.3152  ]\n",
      " [  43.839413  -67.53968  -142.61398  ...   78.84571    17.246653\n",
      "   -37.511566]\n",
      " [ 209.74535   -38.94636   -57.299988 ...   97.86541   126.144646\n",
      "    75.9936  ]\n",
      " ...\n",
      " [ -24.119297  -59.03662  -105.70007  ...  162.62907    69.89179\n",
      "   -10.81326 ]\n",
      " [  37.232277  -97.58978  -107.391754 ...  -89.335      87.85077\n",
      "   -55.217102]\n",
      " [-114.6289    -40.85752     8.5603   ... -104.24077  -159.2414\n",
      "   -87.373566]]\n",
      "[[ -10.513738    -2.8576562   35.931572  ...   86.9844     -62.661915\n",
      "    30.315174 ]\n",
      " [  43.83945    -67.539665  -142.61395   ...   78.84573     17.246628\n",
      "   -37.511547 ]\n",
      " [ 209.74533    -38.946365   -57.299965  ...   97.8654     126.144684\n",
      "    75.99359  ]\n",
      " ...\n",
      " [ -24.119337   -59.03658   -105.700066  ...  162.62909     69.891785\n",
      "   -10.813235 ]\n",
      " [  37.232243   -97.589745  -107.39173   ...  -89.335       87.850815\n",
      "   -55.217133 ]\n",
      " [-114.628876   -40.85749      8.560303  ... -104.240814  -159.2414\n",
      "   -87.373566 ]]\n",
      "-0.657777\n",
      "CPU time: 2.3551881313323975s, GPU time: 9.733412742614746s, kernel time: 9.484299898147583s\n"
     ]
    }
   ],
   "source": [
    "A, B = random_matrix(10000)\n",
    "print(A.shape)\n",
    "print(B.shape)\n",
    "\n",
    "cpu_start=time.time()\n",
    "total_kernel_time=0.0\n",
    "C_cpu, cpu_time = matrix_multiply_cpu(A, B)\n",
    "total_cpu_time=time.time()-cpu_start\n",
    "gpu_start=time.time()\n",
    "C, kernel_time, gpu_time =  matrix_multiply_gpu(A, B)\n",
    "C_torch, torch_time, torch_kernel_time = matrix_multiply_torch(A,B)\n",
    "print(f\"CPU time: {total_cpu_time}s, GPU time: {gpu_time}s, kernel time: {kernel_time}s, Torch time: {torch_time}s, Torch kernel time: {torch_kernel_time}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MapReduce_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
